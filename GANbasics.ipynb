{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Hyunjulie/Basic_ML/blob/master/GANbasics.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "CYKc3VIffcV5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "GAN is a generative model that learns the probability distribution (or data distribution) of the training examples it is given\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Generator: Tries to fool the discriminator (Create fake images)\n",
        "\n",
        "Discrimator: Distinguish whether the image is real \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "* Data: MNIST Training images \n",
        "* Generator network: takes in a random noise vector and produces a synthetic image \n",
        "* Discriminator network (CNN): learns to distinguish between real / synthetic image --> binary classifier (1 for real, 0 for fake image)\n",
        "* Opimization Procedure: updates both networks through Stochastic Gradient Descent \n",
        "* Use Tensorflow "
      ]
    },
    {
      "metadata": {
        "id": "05VN2VvFfg79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "71f76625-301b-457e-f503-0e2c48b16a0a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Loading MNIST Image \n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-3527f021ae5b>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S68iSV9vg5XR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b22f6c7-c834-48d8-c9e7-232bf7ff6acb"
      },
      "cell_type": "code",
      "source": [
        "# mnist variable contains both images and their labels -> extract only the images (size: 28 * 28)\n",
        "x_train = mnist.train.images[:55000, :]\n",
        "x_train.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "VIzguK1yhYxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3de8e9c0-8945-4f91-e4d2-1430bc3b3a7f"
      },
      "cell_type": "code",
      "source": [
        "#Sample image \n",
        "randNum = random.randint(0,55000)\n",
        "image = x_train[randNum].reshape([28,28])\n",
        "plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQZcyYNClDBh0KQP/B0XRy/AfTwluAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdab129bb00>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "D286vD1Ohr_s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Discriminator Network \n",
        "--- \n",
        "CNN Classifier \n",
        "- input: 28 X 28  X 1 (black/white)\n",
        "- output: (None, 2) - since it's a binary classifier "
      ]
    },
    {
      "metadata": {
        "id": "SV9HsGn5hpKx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(x, W):\n",
        "  return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def avg_pool_2x2(x):\n",
        "  return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C7AzpA33iKdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator(x_image, reuse=False):\n",
        "    with tf.variable_scope('discriminator') as scope:\n",
        "        if (reuse):\n",
        "            tf.get_variable_scope().reuse_variables()\n",
        "            \n",
        "        #First Conv and Pool Layers\n",
        "        W_conv1 = tf.get_variable('d_wconv1', [5, 5, 1, 8], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        b_conv1 = tf.get_variable('d_bconv1', [8], initializer=tf.constant_initializer(0))\n",
        "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
        "        h_pool1 = avg_pool_2x2(h_conv1)\n",
        "\n",
        "        #Second Conv and Pool Layers\n",
        "        W_conv2 = tf.get_variable('d_wconv2', [5, 5, 8, 16], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        b_conv2 = tf.get_variable('d_bconv2', [16], initializer=tf.constant_initializer(0))\n",
        "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
        "        h_pool2 = avg_pool_2x2(h_conv2)\n",
        "\n",
        "        #First Fully Connected Layer\n",
        "        W_fc1 = tf.get_variable('d_wfc1', [7 * 7 * 16, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        b_fc1 = tf.get_variable('d_bfc1', [32], initializer=tf.constant_initializer(0))\n",
        "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*16])\n",
        "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
        "\n",
        "        #Second Fully Connected Layer\n",
        "        W_fc2 = tf.get_variable('d_wfc2', [32, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        b_fc2 = tf.get_variable('d_bfc2', [1], initializer=tf.constant_initializer(0))\n",
        "\n",
        "        #Final Layer\n",
        "        y_conv=(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
        "    return y_conv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmBoB77LmnEb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generator Network\n",
        "---\n",
        "Based on the [DCGAN Paper](https://arxiv.org/pdf/1511.06434v2.pdf)\n",
        "\n",
        "Similar with reverse ConvNet\n",
        "\n",
        "Generator: seeks to take d-dimensional noise vector and upsample it to become 28 X 28 image \n",
        "- Done by convolutional transpose layer (deconvolutional)\n",
        "- ReLUs and Batch Normalization is used to stabilize the outputs of each layer \n",
        "\n",
        "* [Conv Transpose --> ReLU --> Batch Norm] is repeated 4 times \n",
        "- Output volume grows larger and larger until 28 X 28 X 1 image is formed \n",
        "- z is a random noise"
      ]
    },
    {
      "metadata": {
        "id": "HxkRmWipmjAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(z, batch_size, z_dim, reuse=False):\n",
        "    with tf.variable_scope('generator') as scope:\n",
        "        if (reuse):\n",
        "            tf.get_variable_scope().reuse_variables()\n",
        "        g_dim = 64 #Number of filters of first layer of generator \n",
        "        c_dim = 1 #Color dimension of output (MNIST is grayscale, so c_dim = 1 for us)\n",
        "        s = 28 #Output size of the image\n",
        "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16) #We want to slowly upscale the image, so these values will help\n",
        "                                                                  #make that change gradual.\n",
        "\n",
        "        h0 = tf.reshape(z, [batch_size, s16+1, s16+1, 25])\n",
        "        h0 = tf.nn.relu(h0)\n",
        "        #Dimensions of h0 = batch_size x 2 x 2 x 25\n",
        "\n",
        "        #First DeConv Layer\n",
        "        output1_shape = [batch_size, s8, s8, g_dim*4]\n",
        "        W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], \n",
        "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]], initializer=tf.constant_initializer(.1))\n",
        "        H_conv1 = tf.nn.conv2d_transpose(h0, W_conv1, output_shape=output1_shape, \n",
        "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv1\n",
        "        H_conv1 = tf.contrib.layers.batch_norm(inputs = H_conv1, center=True, scale=True, is_training=True, scope=\"g_bn1\")\n",
        "        H_conv1 = tf.nn.relu(H_conv1)\n",
        "        #Dimensions of H_conv1 = batch_size x 3 x 3 x 256\n",
        "\n",
        "        #Second DeConv Layer\n",
        "        output2_shape = [batch_size, s4 - 1, s4 - 1, g_dim*2]\n",
        "        W_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(H_conv1.get_shape()[-1])], \n",
        "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]], initializer=tf.constant_initializer(.1))\n",
        "        H_conv2 = tf.nn.conv2d_transpose(H_conv1, W_conv2, output_shape=output2_shape, \n",
        "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv2\n",
        "        H_conv2 = tf.contrib.layers.batch_norm(inputs = H_conv2, center=True, scale=True, is_training=True, scope=\"g_bn2\")\n",
        "        H_conv2 = tf.nn.relu(H_conv2)\n",
        "        #Dimensions of H_conv2 = batch_size x 6 x 6 x 128\n",
        "\n",
        "        #Third DeConv Layer\n",
        "        output3_shape = [batch_size, s2 - 2, s2 - 2, g_dim*1]\n",
        "        W_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(H_conv2.get_shape()[-1])], \n",
        "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], initializer=tf.constant_initializer(.1))\n",
        "        H_conv3 = tf.nn.conv2d_transpose(H_conv2, W_conv3, output_shape=output3_shape, \n",
        "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n",
        "        H_conv3 = tf.contrib.layers.batch_norm(inputs = H_conv3, center=True, scale=True, is_training=True, scope=\"g_bn3\")\n",
        "        H_conv3 = tf.nn.relu(H_conv3)\n",
        "        #Dimensions of H_conv3 = batch_size x 12 x 12 x 64\n",
        "\n",
        "        #Fourth DeConv Layer\n",
        "        output4_shape = [batch_size, s, s, c_dim]\n",
        "        W_conv4 = tf.get_variable('g_wconv4', [5, 5, output4_shape[-1], int(H_conv3.get_shape()[-1])], \n",
        "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]], initializer=tf.constant_initializer(.1))\n",
        "        H_conv4 = tf.nn.conv2d_transpose(H_conv3, W_conv4, output_shape=output4_shape, \n",
        "                                         strides=[1, 2, 2, 1], padding='VALID') + b_conv4\n",
        "        H_conv4 = tf.nn.tanh(H_conv4)\n",
        "        #Dimensions of H_conv4 = batch_size x 28 x 28 x 1\n",
        "\n",
        "    return H_conv4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jiugXbvun9fg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "858987dc-b00f-48ce-f3ba-c40dc5f97a59"
      },
      "cell_type": "code",
      "source": [
        "#Examine a untrained generator\n",
        "sess = tf.Session()\n",
        "z_dimensions = 100\n",
        "z_test_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])\n",
        "sample_image = generator(z_test_placeholder, 1, z_dimensions)\n",
        "test_z = np.random.normal(-1, 1, [1,z_dimensions])\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "temp = (sess.run(sample_image, feed_dict={z_test_placeholder: test_z}))\n",
        "\n",
        "my_i = temp.squeeze() #.squeeze() removes dimensions of size 1 from the shape of a tensor \n",
        "plt.imshow(my_i, cmap='gray_r')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzjGPuOYNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdaa143b128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lxIFCq9ts7jQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "tf.reset_default_graph() \n",
        "#Changed batch size from 1 to 16 --> need to reset tensorflow graph\n",
        "\n",
        "sess = tf.Session()\n",
        "x_placeholder = tf.placeholder(\"float\", shape = [None,28,28,1]) #input images to the discriminator \n",
        "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions]) #random noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JlJ8rC-kxLDU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loss Function\n",
        "---\n",
        "\n",
        "Generator wants the discriminator to output a 1 for its fake image \n",
        "- Compute the loss between Dg and label of 1 \n",
        "- use tf.nn.sigmoid_cross_entropy_with_logits function \n",
        "* \"with logits\": function will operate on unscaled values (instead of using a softmax function to squish the output activations to probability values betwen 0 and 1, return the unscaled value of the matrix multiplication - Discriminator's last layer does not have softmax or sigmoid)\n",
        "\n",
        "\n",
        "Discriminator\n",
        "Goal: get the correct label (1 for MNIST real images, and 0 for generated images)\n",
        "- Need to compute 2 losses: loss between Dx and the correct labels of 1 and loss between Dg and the correct label of 0 \n",
        "- Simply add the two losses "
      ]
    },
    {
      "metadata": {
        "id": "LPdSQtQ6xNrP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dx holds discriminator prediction probabilities for the real MNIST images\n",
        "Dx = discriminator(x_placeholder)\n",
        "\n",
        "# Gz holds generated images\n",
        "Gz = generator(z_placeholder, batch_size, z_dimensions)\n",
        "\n",
        "# Dg holds discriminator prediction probabilities for generated images \n",
        "Dg = discriminator(Gz, reuse=True)\n",
        "\n",
        "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))\n",
        "\n",
        "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
        "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\n",
        "d_loss = d_loss_real + d_loss_fake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1nh6yvdHzwgT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Optimizers & Training\n",
        "---\n",
        "\n",
        "Generator: needs to only update the generator's weights, not those of the discriminator \n",
        "- Create 2 lists: one with discriminator's weights and one with generator's weights\n",
        "* naming all variables come in handy \n"
      ]
    },
    {
      "metadata": {
        "id": "5NnzYX380Blh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8bf3b37-26ac-4651-9415-22371b31c3ee"
      },
      "cell_type": "code",
      "source": [
        "tvars = tf.trainable_variables()\n",
        "d_vars = [var for var in tvars if 'd_' in var.name]\n",
        "g_vars = [var for var in tvars if 'g_' in var.name]\n",
        "\n",
        "print(tf.get_variable_scope().reuse)\n",
        "adam = tf.train.AdamOptimizer(learning_rate=0.0002)\n",
        "trainerD = adam.minimize(d_loss, var_list=d_vars)\n",
        "trainerG = adam.minimize(g_loss, var_list=g_vars)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N63uE5s53wU-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training Loops**\n",
        "\n",
        "For every iteration, there are two updates \n",
        "- Discriminator: Take a batch of images from MNIST variable (positive examples) & images made by the generator (negative examples)\n",
        "- Generator: Feed in a random z vector to the generator and pass that output to the discriminator to obtain a probability score (Dg) --> Loss function updates only the generator's weights & biases\n"
      ]
    },
    {
      "metadata": {
        "id": "uuSWSChX0isv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "iterations = 300\n",
        "for i in range(iterations):\n",
        "  z_batch = np.random.normal(-1, 1, size=[batch_size, z_dimensions])\n",
        "  real_image_batch = mnist.train.next_batch(batch_size)\n",
        "  real_image_batch = np.reshape(real_image_batch[0], [batch_size, 28, 28, 1])\n",
        "\n",
        "  #Update discriminator \n",
        "  _, dLoss = sess.run([trainerD, d_loss], feed_dict={z_placeholder:z_batch, x_placeholder:real_image_batch})\n",
        "  #Update generator\n",
        "  _, gLoss = sess.run([trainerG, g_loss], feed_dict={z_placeholder:z_batch})\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B729s0vd5KYh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample_image = generator(z_placeholder, 1, z_dimensions)\n",
        "z_batch = np.random.normal(-1, 1, size=[1, z_dimensions])\n",
        "temp = (sess.run(sample_image, feed_dict={z_placeholder: z_batch}))\n",
        "my_i = temp.squeeze()\n",
        "plt.imshow(my_i, cmap='gray_r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2yvQU1E75pFL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}